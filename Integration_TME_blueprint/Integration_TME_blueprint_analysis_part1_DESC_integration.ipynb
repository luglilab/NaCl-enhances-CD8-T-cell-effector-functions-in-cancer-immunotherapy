{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SP025 Integration analysis Integration TME part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import colors\n",
    "import seaborn as sb\n",
    "#from gprofiler import GProfiler\n",
    "#import loompy as lp\n",
    "#import rpy2.rinterface_lib.callbacks\n",
    "import logging\n",
    "#import scrublet as scr\n",
    "#from rpy2.robjects import pandas2ri\n",
    "#import anndata2ri\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os              \n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import desc\n",
    "#import keras\n",
    "import tensorflow as tf\n",
    "from time import time                                                       \n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset Lung/BC/CRC/Ovarian CD8 + CD4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "adataLung = sc.read_h5ad(\"/home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/Lung_output/adata_lung_Tcell.h5ad\")\n",
    "adataBC = sc.read_h5ad(\"/home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/BC_output/adata_bc_Tcell.h5ad\")\n",
    "adataCRC = sc.read_h5ad(\"/home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/CRC_output/adata_CRC_Tcell_sub.h5ad\")\n",
    "adataOvarian = sc.read_h5ad(\"/home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/Ovarian_output/adata_oc_Tcell_sub.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adataLung.concatenate(adataBC,adataCRC,adataOvarian,index_unique=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = adata.obs[['CellFromTumor','PatientNumber','TumorType']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs['CellFromTumor']  == 1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"/home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/Integrated/Concatenate_T_cell.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31018, 11358)\n"
     ]
    }
   ],
   "source": [
    "print(adata.X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute DESC algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2 = adata.copy()\n",
    "\n",
    "sc.pp.normalize_per_cell(adata2, counts_per_cell_after=1e4)\n",
    "sc.pp.log1p(adata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2=desc.scale_bygroup(adata2,\"TumorType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to process resolution= 0.4\n",
      "The number of cpu in your computer is 32\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "use_ae_weights=False, the program will rerun autoencoder\n",
      "Pretraining the 1th layer...\n",
      "learning rate = 0.1\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 17s 542us/sample - loss: 0.7331\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 16s 518us/sample - loss: 0.7300\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 16s 510us/sample - loss: 0.7284\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 17s 546us/sample - loss: 0.7271\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 19s 612us/sample - loss: 0.7260\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 19s 611us/sample - loss: 0.7245\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 19s 622us/sample - loss: 0.7228\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 19s 620us/sample - loss: 0.7212\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 19s 616us/sample - loss: 0.7198\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 19s 619us/sample - loss: 0.7187\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 19s 621us/sample - loss: 0.7178\n",
      "Epoch 12/50\n",
      "31018/31018 [==============================] - 19s 627us/sample - loss: 0.7171\n",
      "Epoch 13/50\n",
      "31018/31018 [==============================] - 19s 619us/sample - loss: 0.7166\n",
      "Epoch 14/50\n",
      "31018/31018 [==============================] - 18s 589us/sample - loss: 0.7162\n",
      "Epoch 15/50\n",
      "31018/31018 [==============================] - 16s 530us/sample - loss: 0.7158\n",
      "Epoch 16/50\n",
      "31018/31018 [==============================] - 16s 531us/sample - loss: 0.7156\n",
      "Epoch 17/50\n",
      "31018/31018 [==============================] - 16s 529us/sample - loss: 0.7153\n",
      "Epoch 18/50\n",
      "31018/31018 [==============================] - 17s 533us/sample - loss: 0.7151\n",
      "Epoch 19/50\n",
      "31018/31018 [==============================] - 16s 517us/sample - loss: 0.7148\n",
      "Epoch 20/50\n",
      "31018/31018 [==============================] - 16s 521us/sample - loss: 0.7146\n",
      "Epoch 21/50\n",
      "31018/31018 [==============================] - 16s 524us/sample - loss: 0.7143\n",
      "Epoch 22/50\n",
      "31018/31018 [==============================] - 16s 528us/sample - loss: 0.7141\n",
      "Epoch 23/50\n",
      "31018/31018 [==============================] - 14s 456us/sample - loss: 0.7139\n",
      "Epoch 24/50\n",
      "31018/31018 [==============================] - 13s 415us/sample - loss: 0.7136\n",
      "Epoch 25/50\n",
      "31018/31018 [==============================] - 13s 410us/sample - loss: 0.7134\n",
      "Epoch 26/50\n",
      "31018/31018 [==============================] - 13s 412us/sample - loss: 0.7131\n",
      "Epoch 27/50\n",
      "31018/31018 [==============================] - 14s 447us/sample - loss: 0.7129\n",
      "Epoch 28/50\n",
      "31018/31018 [==============================] - 16s 528us/sample - loss: 0.7127\n",
      "Epoch 29/50\n",
      "31018/31018 [==============================] - 16s 512us/sample - loss: 0.7124\n",
      "Epoch 30/50\n",
      "31018/31018 [==============================] - 16s 502us/sample - loss: 0.7122\n",
      "Epoch 31/50\n",
      "31018/31018 [==============================] - 16s 504us/sample - loss: 0.7120\n",
      "Epoch 32/50\n",
      "31018/31018 [==============================] - 16s 518us/sample - loss: 0.7118\n",
      "Epoch 33/50\n",
      "31018/31018 [==============================] - 16s 519us/sample - loss: 0.7116\n",
      "Epoch 34/50\n",
      "31018/31018 [==============================] - 16s 515us/sample - loss: 0.7114\n",
      "Epoch 35/50\n",
      "31018/31018 [==============================] - 16s 523us/sample - loss: 0.7112\n",
      "Epoch 36/50\n",
      "31018/31018 [==============================] - 16s 527us/sample - loss: 0.7109\n",
      "Epoch 37/50\n",
      "31018/31018 [==============================] - 16s 517us/sample - loss: 0.7108\n",
      "Epoch 38/50\n",
      "31018/31018 [==============================] - 16s 529us/sample - loss: 0.7106\n",
      "Epoch 39/50\n",
      "31018/31018 [==============================] - 17s 535us/sample - loss: 0.7104\n",
      "Epoch 40/50\n",
      "31018/31018 [==============================] - 16s 523us/sample - loss: 0.7102\n",
      "Epoch 41/50\n",
      "31018/31018 [==============================] - 16s 514us/sample - loss: 0.7100\n",
      "Epoch 42/50\n",
      "31018/31018 [==============================] - 17s 562us/sample - loss: 0.7098\n",
      "Epoch 43/50\n",
      "31018/31018 [==============================] - 18s 589us/sample - loss: 0.7097\n",
      "Epoch 44/50\n",
      "31018/31018 [==============================] - 18s 596us/sample - loss: 0.7095\n",
      "Epoch 45/50\n",
      "31018/31018 [==============================] - 19s 611us/sample - loss: 0.7093\n",
      "Epoch 46/50\n",
      "31018/31018 [==============================] - 19s 597us/sample - loss: 0.7091\n",
      "Epoch 47/50\n",
      "31018/31018 [==============================] - 19s 609us/sample - loss: 0.7090\n",
      "Epoch 48/50\n",
      "31018/31018 [==============================] - 19s 612us/sample - loss: 0.7089\n",
      "Epoch 49/50\n",
      "31018/31018 [==============================] - 19s 611us/sample - loss: 0.7087\n",
      "Epoch 50/50\n",
      "31018/31018 [==============================] - 18s 590us/sample - loss: 0.7086\n",
      "learning rate = 0.01\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 19s 599us/sample - loss: 0.7084\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 16s 532us/sample - loss: 0.7085\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 17s 545us/sample - loss: 0.7084\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 18s 585us/sample - loss: 0.7084\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 18s 590us/sample - loss: 0.7084\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 18s 596us/sample - loss: 0.7084\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 19s 603us/sample - loss: 0.7084\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 18s 591us/sample - loss: 0.7083\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 17s 544us/sample - loss: 0.7083\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 16s 528us/sample - loss: 0.7083\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 18s 584us/sample - loss: 0.7083\n",
      "Epoch 12/50\n",
      "31018/31018 [==============================] - 19s 606us/sample - loss: 0.7083\n",
      "Epoch 13/50\n",
      "31018/31018 [==============================] - 19s 603us/sample - loss: 0.7083\n",
      "Epoch 14/50\n",
      "31018/31018 [==============================] - 19s 597us/sample - loss: 0.7083\n",
      "Epoch 15/50\n",
      "31018/31018 [==============================] - 19s 602us/sample - loss: 0.7083\n",
      "Epoch 16/50\n",
      "31018/31018 [==============================] - 19s 605us/sample - loss: 0.7082\n",
      "Epoch 17/50\n",
      "31018/31018 [==============================] - 18s 594us/sample - loss: 0.7082\n",
      "Epoch 18/50\n",
      "31018/31018 [==============================] - 18s 580us/sample - loss: 0.7082\n",
      "Epoch 19/50\n",
      "31018/31018 [==============================] - 18s 577us/sample - loss: 0.7082\n",
      "Epoch 20/50\n",
      "31018/31018 [==============================] - 19s 608us/sample - loss: 0.7082\n",
      "Epoch 21/50\n",
      "31018/31018 [==============================] - 19s 612us/sample - loss: 0.7082\n",
      "Epoch 22/50\n",
      "31018/31018 [==============================] - 19s 625us/sample - loss: 0.7081\n",
      "Epoch 23/50\n",
      "31018/31018 [==============================] - 19s 622us/sample - loss: 0.7081\n",
      "Epoch 24/50\n",
      "31018/31018 [==============================] - 19s 613us/sample - loss: 0.7081\n",
      "Epoch 25/50\n",
      "31018/31018 [==============================] - 19s 623us/sample - loss: 0.7081\n",
      "Epoch 26/50\n",
      "31018/31018 [==============================] - 20s 631us/sample - loss: 0.7081\n",
      "Epoch 27/50\n",
      "31018/31018 [==============================] - 19s 617us/sample - loss: 0.7081\n",
      "Epoch 28/50\n",
      "31018/31018 [==============================] - 20s 634us/sample - loss: 0.7081\n",
      "Epoch 29/50\n",
      "31018/31018 [==============================] - 19s 603us/sample - loss: 0.7080\n",
      "Epoch 30/50\n",
      "31018/31018 [==============================] - 18s 577us/sample - loss: 0.7081\n",
      "Epoch 31/50\n",
      "31018/31018 [==============================] - 17s 557us/sample - loss: 0.7080\n",
      "Epoch 32/50\n",
      "31018/31018 [==============================] - 17s 536us/sample - loss: 0.7080\n",
      "Epoch 33/50\n",
      "31018/31018 [==============================] - 18s 594us/sample - loss: 0.7080\n",
      "Epoch 34/50\n",
      "31018/31018 [==============================] - 18s 590us/sample - loss: 0.7080\n",
      "Epoch 35/50\n",
      "31018/31018 [==============================] - 19s 626us/sample - loss: 0.7080\n",
      "Epoch 36/50\n",
      "31018/31018 [==============================] - 19s 624us/sample - loss: 0.7079\n",
      "Epoch 37/50\n",
      "31018/31018 [==============================] - 19s 622us/sample - loss: 0.7079\n",
      "Epoch 38/50\n",
      "31018/31018 [==============================] - 18s 581us/sample - loss: 0.7080\n",
      "Epoch 39/50\n",
      "31018/31018 [==============================] - 17s 560us/sample - loss: 0.7079\n",
      "Epoch 40/50\n",
      "31018/31018 [==============================] - 18s 572us/sample - loss: 0.7079\n",
      "Epoch 41/50\n",
      "31018/31018 [==============================] - 18s 593us/sample - loss: 0.7079\n",
      "Epoch 42/50\n",
      "31018/31018 [==============================] - 19s 605us/sample - loss: 0.7079\n",
      "Epoch 43/50\n",
      "31018/31018 [==============================] - 16s 529us/sample - loss: 0.7079\n",
      "Epoch 44/50\n",
      "31018/31018 [==============================] - 16s 504us/sample - loss: 0.7078\n",
      "Epoch 45/50\n",
      "31018/31018 [==============================] - 16s 517us/sample - loss: 0.7078\n",
      "Epoch 46/50\n",
      "31018/31018 [==============================] - 17s 543us/sample - loss: 0.7078\n",
      "Epoch 47/50\n",
      "31018/31018 [==============================] - 17s 555us/sample - loss: 0.7078\n",
      "Epoch 48/50\n",
      "31018/31018 [==============================] - 17s 560us/sample - loss: 0.7078\n",
      "Epoch 49/50\n",
      "31018/31018 [==============================] - 16s 531us/sample - loss: 0.7078\n",
      "Epoch 50/50\n",
      "31018/31018 [==============================] - 17s 549us/sample - loss: 0.7078\n",
      "learning rate = 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 17s 552us/sample - loss: 0.7078\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 16s 508us/sample - loss: 0.7078\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 17s 561us/sample - loss: 0.7078\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 16s 503us/sample - loss: 0.7078\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 17s 552us/sample - loss: 0.7078\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 18s 582us/sample - loss: 0.7078\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 18s 575us/sample - loss: 0.7078\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 19s 603us/sample - loss: 0.7078\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 19s 598us/sample - loss: 0.7078\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 19s 598us/sample - loss: 0.7078\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 18s 586us/sample - loss: 0.7077\n",
      "Epoch 00011: early stopping\n",
      "The 1th layer has been pretrained.\n",
      "Pretraining the 2th layer...\n",
      "learning rate = 0.1\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 1s 31us/sample - loss: 0.4672\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2869\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2539\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2373\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 0s 9us/sample - loss: 0.2300\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 0s 9us/sample - loss: 0.2241\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 0s 7us/sample - loss: 0.2189\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2182\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2170\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 0s 10us/sample - loss: 0.2140\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2142\n",
      "Epoch 12/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2154\n",
      "Epoch 13/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2128\n",
      "Epoch 14/50\n",
      "31018/31018 [==============================] - 0s 9us/sample - loss: 0.2138\n",
      "Epoch 15/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2119\n",
      "Epoch 16/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2126\n",
      "Epoch 17/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2114\n",
      "Epoch 18/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2109\n",
      "Epoch 19/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2123\n",
      "Epoch 20/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2090\n",
      "Epoch 21/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2104\n",
      "Epoch 22/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2101\n",
      "Epoch 23/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2108\n",
      "Epoch 24/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2092\n",
      "Epoch 25/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2120\n",
      "Epoch 26/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2093\n",
      "Epoch 27/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2091\n",
      "Epoch 28/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2104\n",
      "Epoch 29/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2088\n",
      "Epoch 30/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2121\n",
      "Epoch 31/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2088\n",
      "Epoch 32/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2090\n",
      "Epoch 33/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2096\n",
      "Epoch 34/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2080\n",
      "Epoch 35/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2095\n",
      "Epoch 36/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2074\n",
      "Epoch 37/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2104\n",
      "Epoch 38/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2093\n",
      "Epoch 39/50\n",
      "31018/31018 [==============================] - 0s 9us/sample - loss: 0.2083\n",
      "Epoch 40/50\n",
      "31018/31018 [==============================] - 0s 7us/sample - loss: 0.2085\n",
      "Epoch 41/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2084\n",
      "Epoch 42/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2089\n",
      "Epoch 43/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2083\n",
      "Epoch 44/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2079\n",
      "Epoch 45/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2079\n",
      "Epoch 46/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2124\n",
      "Epoch 00046: early stopping\n",
      "learning rate = 0.01\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 1s 20us/sample - loss: 0.2037\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2024\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.2007\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1995\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1995\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1996\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1979\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1990\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1997\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1983\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 0s 9us/sample - loss: 0.1985\n",
      "Epoch 12/50\n",
      "31018/31018 [==============================] - 0s 10us/sample - loss: 0.1994\n",
      "Epoch 13/50\n",
      "31018/31018 [==============================] - 0s 9us/sample - loss: 0.1976\n",
      "Epoch 14/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1977\n",
      "Epoch 15/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1984\n",
      "Epoch 16/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1990\n",
      "Epoch 17/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1982\n",
      "Epoch 18/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1985\n",
      "Epoch 19/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1989\n",
      "Epoch 20/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1985\n",
      "Epoch 21/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1982\n",
      "Epoch 22/50\n",
      "31018/31018 [==============================] - 0s 9us/sample - loss: 0.1976\n",
      "Epoch 23/50\n",
      "31018/31018 [==============================] - 0s 9us/sample - loss: 0.1996\n",
      "Epoch 00023: early stopping\n",
      "learning rate = 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 1s 23us/sample - loss: 0.1972\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1984\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1977\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1973\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1972\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 0s 7us/sample - loss: 0.1976\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1961\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1972\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1981\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1966\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1969\n",
      "Epoch 12/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1979\n",
      "Epoch 13/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1962\n",
      "Epoch 14/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1963\n",
      "Epoch 15/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1972\n",
      "Epoch 16/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1977\n",
      "Epoch 17/50\n",
      "31018/31018 [==============================] - 0s 8us/sample - loss: 0.1969\n",
      "Epoch 00017: early stopping\n",
      "The 2th layer has been pretrained.\n",
      "Copying layer-wise pretrained weights to deep autoencoders\n",
      "Fine-tuning autoencoder end-to-end\n",
      "learning rate = 1\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 12s 378us/sample - loss: 0.7065\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 10s 321us/sample - loss: 0.7056\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 9s 305us/sample - loss: 0.7050\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 10s 309us/sample - loss: 0.7045\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 9s 304us/sample - loss: 0.7040\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 10s 314us/sample - loss: 0.7036\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 9s 303us/sample - loss: 0.7032\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 9s 293us/sample - loss: 0.7029\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 9s 303us/sample - loss: 0.7026\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 9s 292us/sample - loss: 0.7023\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 10s 317us/sample - loss: 0.7020\n",
      "Epoch 12/50\n",
      "31018/31018 [==============================] - 10s 306us/sample - loss: 0.7018\n",
      "Epoch 13/50\n",
      "31018/31018 [==============================] - 11s 347us/sample - loss: 0.7015\n",
      "Epoch 14/50\n",
      "31018/31018 [==============================] - 12s 376us/sample - loss: 0.7013\n",
      "Epoch 15/50\n",
      "31018/31018 [==============================] - 12s 373us/sample - loss: 0.7011\n",
      "Epoch 16/50\n",
      "31018/31018 [==============================] - 12s 384us/sample - loss: 0.7009\n",
      "Epoch 17/50\n",
      "31018/31018 [==============================] - 10s 336us/sample - loss: 0.7007\n",
      "Epoch 18/50\n",
      "31018/31018 [==============================] - 10s 333us/sample - loss: 0.7006\n",
      "Epoch 19/50\n",
      "31018/31018 [==============================] - 10s 334us/sample - loss: 0.7004\n",
      "Epoch 20/50\n",
      "31018/31018 [==============================] - 10s 333us/sample - loss: 0.7003\n",
      "Epoch 21/50\n",
      "31018/31018 [==============================] - 10s 317us/sample - loss: 0.7001\n",
      "Epoch 22/50\n",
      "31018/31018 [==============================] - 9s 293us/sample - loss: 0.7000\n",
      "Epoch 23/50\n",
      "31018/31018 [==============================] - 10s 320us/sample - loss: 0.6999\n",
      "Epoch 24/50\n",
      "31018/31018 [==============================] - 10s 319us/sample - loss: 0.6997\n",
      "Epoch 25/50\n",
      "31018/31018 [==============================] - 11s 353us/sample - loss: 0.6996\n",
      "Epoch 26/50\n",
      "31018/31018 [==============================] - 11s 353us/sample - loss: 0.6995\n",
      "Epoch 27/50\n",
      "31018/31018 [==============================] - 11s 355us/sample - loss: 0.6994\n",
      "Epoch 28/50\n",
      "31018/31018 [==============================] - 11s 345us/sample - loss: 0.6993\n",
      "Epoch 29/50\n",
      "31018/31018 [==============================] - 10s 328us/sample - loss: 0.6992\n",
      "Epoch 30/50\n",
      "31018/31018 [==============================] - 11s 346us/sample - loss: 0.6991\n",
      "Epoch 31/50\n",
      "31018/31018 [==============================] - 11s 340us/sample - loss: 0.6990\n",
      "Epoch 32/50\n",
      "31018/31018 [==============================] - 11s 340us/sample - loss: 0.6989\n",
      "Epoch 33/50\n",
      "31018/31018 [==============================] - 11s 348us/sample - loss: 0.6989\n",
      "Epoch 34/50\n",
      "31018/31018 [==============================] - 10s 335us/sample - loss: 0.6988\n",
      "Epoch 35/50\n",
      "31018/31018 [==============================] - 10s 320us/sample - loss: 0.6987\n",
      "Epoch 36/50\n",
      "31018/31018 [==============================] - 10s 323us/sample - loss: 0.6986\n",
      "Epoch 37/50\n",
      "31018/31018 [==============================] - 10s 315us/sample - loss: 0.6986\n",
      "Epoch 38/50\n",
      "31018/31018 [==============================] - 10s 321us/sample - loss: 0.6985\n",
      "Epoch 39/50\n",
      "31018/31018 [==============================] - 10s 312us/sample - loss: 0.6984\n",
      "Epoch 40/50\n",
      "31018/31018 [==============================] - 10s 330us/sample - loss: 0.6984\n",
      "Epoch 41/50\n",
      "31018/31018 [==============================] - 11s 351us/sample - loss: 0.6983\n",
      "Epoch 42/50\n",
      "31018/31018 [==============================] - 11s 357us/sample - loss: 0.6982\n",
      "Epoch 43/50\n",
      "31018/31018 [==============================] - 11s 346us/sample - loss: 0.6982\n",
      "Epoch 44/50\n",
      "31018/31018 [==============================] - 10s 320us/sample - loss: 0.6981\n",
      "Epoch 45/50\n",
      "31018/31018 [==============================] - 11s 350us/sample - loss: 0.6981\n",
      "Epoch 46/50\n",
      "31018/31018 [==============================] - 10s 336us/sample - loss: 0.6980\n",
      "Epoch 47/50\n",
      "31018/31018 [==============================] - 10s 336us/sample - loss: 0.6980\n",
      "Epoch 48/50\n",
      "31018/31018 [==============================] - 10s 319us/sample - loss: 0.6979\n",
      "Epoch 49/50\n",
      "31018/31018 [==============================] - 10s 318us/sample - loss: 0.6979\n",
      "Epoch 50/50\n",
      "31018/31018 [==============================] - 10s 331us/sample - loss: 0.6978\n",
      "learning rate = 0.1\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 12s 373us/sample - loss: 0.6975\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 10s 337us/sample - loss: 0.6975\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 11s 342us/sample - loss: 0.6975\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 11s 359us/sample - loss: 0.6975\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 11s 349us/sample - loss: 0.6975\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 10s 322us/sample - loss: 0.6975\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 10s 331us/sample - loss: 0.6975\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 10s 332us/sample - loss: 0.6975\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 10s 329us/sample - loss: 0.6975\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 10s 338us/sample - loss: 0.6975\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 10s 335us/sample - loss: 0.6975\n",
      "Epoch 00011: early stopping\n",
      "learning rate = 0.01\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 11s 360us/sample - loss: 0.6974\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 11s 365us/sample - loss: 0.6974\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 11s 355us/sample - loss: 0.6974\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 11s 370us/sample - loss: 0.6974\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 10s 326us/sample - loss: 0.6974\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 10s 328us/sample - loss: 0.6974\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 10s 333us/sample - loss: 0.6974\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 11s 347us/sample - loss: 0.6974\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 11s 348us/sample - loss: 0.6974\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 10s 316us/sample - loss: 0.6974\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 10s 322us/sample - loss: 0.6974\n",
      "Epoch 00011: early stopping\n",
      "learning rate = 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 12s 374us/sample - loss: 0.6974\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 10s 314us/sample - loss: 0.6974\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 9s 305us/sample - loss: 0.6974\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 10s 313us/sample - loss: 0.6974\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 10s 333us/sample - loss: 0.6974\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 11s 346us/sample - loss: 0.6974\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 10s 325us/sample - loss: 0.6974\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 10s 337us/sample - loss: 0.6974\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 11s 358us/sample - loss: 0.6974\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 11s 351us/sample - loss: 0.6974\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 11s 349us/sample - loss: 0.6974\n",
      "Epoch 00011: early stopping\n",
      "learning rate = 0.0001\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 10s 327us/sample - loss: 0.6974\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 9s 283us/sample - loss: 0.6974\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 9s 295us/sample - loss: 0.6974\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 10s 312us/sample - loss: 0.6974\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 9s 301us/sample - loss: 0.6974\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 10s 318us/sample - loss: 0.6974\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 10s 327us/sample - loss: 0.6974\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 10s 332us/sample - loss: 0.6974\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 10s 324us/sample - loss: 0.6974\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 11s 344us/sample - loss: 0.6974\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 10s 328us/sample - loss: 0.6974\n",
      "Epoch 00011: early stopping\n",
      "learning rate = 1e-05\n",
      "Train on 31018 samples\n",
      "Epoch 1/50\n",
      "31018/31018 [==============================] - 14s 438us/sample - loss: 0.6974\n",
      "Epoch 2/50\n",
      "31018/31018 [==============================] - 13s 415us/sample - loss: 0.6974\n",
      "Epoch 3/50\n",
      "31018/31018 [==============================] - 12s 386us/sample - loss: 0.6974\n",
      "Epoch 4/50\n",
      "31018/31018 [==============================] - 11s 345us/sample - loss: 0.6974\n",
      "Epoch 5/50\n",
      "31018/31018 [==============================] - 11s 352us/sample - loss: 0.6974\n",
      "Epoch 6/50\n",
      "31018/31018 [==============================] - 11s 339us/sample - loss: 0.6974\n",
      "Epoch 7/50\n",
      "31018/31018 [==============================] - 11s 349us/sample - loss: 0.6974\n",
      "Epoch 8/50\n",
      "31018/31018 [==============================] - 11s 340us/sample - loss: 0.6974\n",
      "Epoch 9/50\n",
      "31018/31018 [==============================] - 10s 325us/sample - loss: 0.6974\n",
      "Epoch 10/50\n",
      "31018/31018 [==============================] - 10s 330us/sample - loss: 0.6974\n",
      "Epoch 11/50\n",
      "31018/31018 [==============================] - 12s 400us/sample - loss: 0.6974\n",
      "Epoch 00011: early stopping\n",
      "Pretraining time is 3075.4500644207\n",
      "Pretrained weights are saved to /home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/Integrated /ae_weights.h5\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.18695596105487136 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 6s 198us/sample - loss: 0.0142\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 6s 203us/sample - loss: 0.0105\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 184us/sample - loss: 0.0088\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 185us/sample - loss: 0.0076\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 168us/sample - loss: 0.0067\n",
      "The value of delta_label of current 2 th iteration is 0.1407892191630666 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 149us/sample - loss: 0.0355\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 149us/sample - loss: 0.0274\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 152us/sample - loss: 0.0222\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 139us/sample - loss: 0.0184\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 130us/sample - loss: 0.0155\n",
      "The value of delta_label of current 3 th iteration is 0.12415371719646656 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 166us/sample - loss: 0.0772\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 6s 187us/sample - loss: 0.0548\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 187us/sample - loss: 0.0415\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 192us/sample - loss: 0.0330\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 170us/sample - loss: 0.0274\n",
      "The value of delta_label of current 4 th iteration is 0.08366110000644787 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 129us/sample - loss: 0.1533\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.1087\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 135us/sample - loss: 0.0855\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 138us/sample - loss: 0.0715\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 136us/sample - loss: 0.0622\n",
      "The value of delta_label of current 5 th iteration is 0.054774646979173384 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 136us/sample - loss: 0.2186\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 141us/sample - loss: 0.1707\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 136us/sample - loss: 0.1445\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.1270\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 136us/sample - loss: 0.1144\n",
      "The value of delta_label of current 6 th iteration is 0.03143336127409891 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 153us/sample - loss: 0.2281\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 123us/sample - loss: 0.1894\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 150us/sample - loss: 0.1684\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 150us/sample - loss: 0.1540\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 140us/sample - loss: 0.1428\n",
      "The value of delta_label of current 7 th iteration is 0.01270230188922561 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 148us/sample - loss: 0.2091\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 131us/sample - loss: 0.1841\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 133us/sample - loss: 0.1709\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 133us/sample - loss: 0.1613\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 135us/sample - loss: 0.1535\n",
      "The value of delta_label of current 8 th iteration is 0.005448449287510477 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 120us/sample - loss: 0.1853\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 117us/sample - loss: 0.1711\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 120us/sample - loss: 0.1628\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 141us/sample - loss: 0.1562\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 133us/sample - loss: 0.1504\n",
      "The value of delta_label of current 9 th iteration is 0.001837642659101167 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 120us/sample - loss: 0.1655\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 122us/sample - loss: 0.1575\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 124us/sample - loss: 0.1527\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 123us/sample - loss: 0.1487\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 134us/sample - loss: 0.1448\n",
      "delta_label  0.0006125475530337224 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "The final prediction cluster is:\n",
      "0    4303\n",
      "1    4174\n",
      "2    3354\n",
      "3    4438\n",
      "4    2825\n",
      "5    4457\n",
      "6    4131\n",
      "7    3336\n",
      "dtype: int64\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 11358)]           0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 64)                726976    \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 8)                 256       \n",
      "=================================================================\n",
      "Total params: 729,312\n",
      "Trainable params: 729,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.4)is: 3347.7763607501984\n",
      "umap finished and added X_umap0.4  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.5\n",
      "The number of cpu in your computer is 32\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Checking whether /home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/Integrated/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.06554412841796875\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.22993100780192147 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 6s 191us/sample - loss: 0.0178\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 6s 182us/sample - loss: 0.0141\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 196us/sample - loss: 0.0123\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 190us/sample - loss: 0.0109\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 170us/sample - loss: 0.0099\n",
      "The value of delta_label of current 2 th iteration is 0.1686440131536527 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 175us/sample - loss: 0.0422\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 6s 182us/sample - loss: 0.0350\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 7s 214us/sample - loss: 0.0300\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 188us/sample - loss: 0.0260\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 154us/sample - loss: 0.0227\n",
      "The value of delta_label of current 3 th iteration is 0.12766780579018636 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 130us/sample - loss: 0.0863\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 6s 181us/sample - loss: 0.0680\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 180us/sample - loss: 0.0553\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.0462\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 143us/sample - loss: 0.0396\n",
      "The value of delta_label of current 4 th iteration is 0.08169449996776065 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 148us/sample - loss: 0.1668\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 152us/sample - loss: 0.1317\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 168us/sample - loss: 0.1101\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.0954\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 115us/sample - loss: 0.0848\n",
      "The value of delta_label of current 5 th iteration is 0.06009413888709782 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 164us/sample - loss: 0.2520\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 143us/sample - loss: 0.2079\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 133us/sample - loss: 0.1798\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 129us/sample - loss: 0.1598\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 135us/sample - loss: 0.1446\n",
      "The value of delta_label of current 6 th iteration is 0.04071829260429428 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 149us/sample - loss: 0.2960\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 129us/sample - loss: 0.2525\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 127us/sample - loss: 0.2249\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 129us/sample - loss: 0.2050\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 119us/sample - loss: 0.1896\n",
      "The value of delta_label of current 7 th iteration is 0.02198723321942098 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 147us/sample - loss: 0.2975\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 140us/sample - loss: 0.2647\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 140us/sample - loss: 0.2444\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 121us/sample - loss: 0.2294\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 124us/sample - loss: 0.2177\n",
      "The value of delta_label of current 8 th iteration is 0.011444967438261655 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.2782\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 138us/sample - loss: 0.2561\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 116us/sample - loss: 0.2427\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 160us/sample - loss: 0.2311\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 156us/sample - loss: 0.2216\n",
      "The value of delta_label of current 9 th iteration is 0.005093816493648849 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 137us/sample - loss: 0.2553\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 126us/sample - loss: 0.2421\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 124us/sample - loss: 0.2336\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 125us/sample - loss: 0.2251\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 148us/sample - loss: 0.2177\n",
      "The value of delta_label of current 10 th iteration is 0.0018698820039976787 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 138us/sample - loss: 0.2351\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 127us/sample - loss: 0.2263\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 131us/sample - loss: 0.2203\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 135us/sample - loss: 0.2145\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 155us/sample - loss: 0.2090\n",
      "delta_label  0.0009027016571023276 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "The final prediction cluster is:\n",
      "0     2155\n",
      "1     3116\n",
      "2     2506\n",
      "3     4106\n",
      "4     3741\n",
      "5     1879\n",
      "6     2700\n",
      "7     1748\n",
      "8     1529\n",
      "9     2911\n",
      "10    3007\n",
      "11    1620\n",
      "dtype: int64\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 11358)]           0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 64)                726976    \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 12)                384       \n",
      "=================================================================\n",
      "Total params: 729,440\n",
      "Trainable params: 729,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.5)is: 306.55175375938416\n",
      "umap finished and added X_umap0.5  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.6\n",
      "The number of cpu in your computer is 32\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Checking whether /home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/Integrated/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.0634770393371582\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.24753369011541684 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 6s 183us/sample - loss: 0.0185\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 171us/sample - loss: 0.0149\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 194us/sample - loss: 0.0132\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 186us/sample - loss: 0.0119\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 6s 193us/sample - loss: 0.0109\n",
      "The value of delta_label of current 2 th iteration is 0.16187375072538526 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 171us/sample - loss: 0.0418\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 163us/sample - loss: 0.0354\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 163us/sample - loss: 0.0309\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 179us/sample - loss: 0.0272\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 125us/sample - loss: 0.0241\n",
      "The value of delta_label of current 3 th iteration is 0.1242181958862596 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 6s 178us/sample - loss: 0.0828\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 166us/sample - loss: 0.0675\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 156us/sample - loss: 0.0563\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 133us/sample - loss: 0.0479\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 167us/sample - loss: 0.0416\n",
      "The value of delta_label of current 4 th iteration is 0.08478947707782578 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 157us/sample - loss: 0.1616\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 152us/sample - loss: 0.1313\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 147us/sample - loss: 0.1116\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 151us/sample - loss: 0.0977\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 152us/sample - loss: 0.0874\n",
      "The value of delta_label of current 5 th iteration is 0.07015281449480947 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 159us/sample - loss: 0.2550\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 6s 184us/sample - loss: 0.2148\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 164us/sample - loss: 0.1877\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 162us/sample - loss: 0.1679\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 151us/sample - loss: 0.1525\n",
      "The value of delta_label of current 6 th iteration is 0.04842349603456058 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 174us/sample - loss: 0.3151\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 151us/sample - loss: 0.2717\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 167us/sample - loss: 0.2427\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 151us/sample - loss: 0.2212\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 150us/sample - loss: 0.2043\n",
      "The value of delta_label of current 7 th iteration is 0.026565220194725642 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 3s 103us/sample - loss: 0.3324\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 3s 99us/sample - loss: 0.2954\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 143us/sample - loss: 0.2705\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.2518\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 139us/sample - loss: 0.2370\n",
      "The value of delta_label of current 8 th iteration is 0.013218131407569798 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 145us/sample - loss: 0.3204\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.2945\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 150us/sample - loss: 0.2770\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 141us/sample - loss: 0.2631\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 136us/sample - loss: 0.2518\n",
      "The value of delta_label of current 9 th iteration is 0.007221613256818621 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 139us/sample - loss: 0.2992\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 132us/sample - loss: 0.2824\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 132us/sample - loss: 0.2705\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 133us/sample - loss: 0.2607\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 128us/sample - loss: 0.2521\n",
      "The value of delta_label of current 10 th iteration is 0.0033206525243407053 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 130us/sample - loss: 0.2782\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 127us/sample - loss: 0.2674\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 136us/sample - loss: 0.2596\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 125us/sample - loss: 0.2523\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 138us/sample - loss: 0.2459\n",
      "The value of delta_label of current 11 th iteration is 0.001418531175446515 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 149us/sample - loss: 0.2601\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 124us/sample - loss: 0.2527\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 126us/sample - loss: 0.2471\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 132us/sample - loss: 0.2419\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 120us/sample - loss: 0.2372\n",
      "The value of delta_label of current 12 th iteration is 0.0010316590366883744 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 149us/sample - loss: 0.2452\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 151us/sample - loss: 0.2403\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 143us/sample - loss: 0.2363\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.2325\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 148us/sample - loss: 0.2291\n",
      "delta_label  0.00035463279386162874 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "The final prediction cluster is:\n",
      "0     2286\n",
      "1     2569\n",
      "2     2002\n",
      "3     2866\n",
      "4     1725\n",
      "5     3094\n",
      "6     3416\n",
      "7     2106\n",
      "8     2580\n",
      "9     1964\n",
      "10    2365\n",
      "11     905\n",
      "12    2267\n",
      "13     873\n",
      "dtype: int64\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 11358)]           0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 64)                726976    \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 14)                448       \n",
      "=================================================================\n",
      "Total params: 729,504\n",
      "Trainable params: 729,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.6)is: 359.67939472198486\n",
      "umap finished and added X_umap0.6  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.7\n",
      "The number of cpu in your computer is 32\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Checking whether /home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/Integrated/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.06291699409484863\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.24479334579921336 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 6s 197us/sample - loss: 0.0181\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 164us/sample - loss: 0.0146\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 180us/sample - loss: 0.0129\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 189us/sample - loss: 0.0116\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 6s 183us/sample - loss: 0.0106\n",
      "The value of delta_label of current 2 th iteration is 0.15300793087884454 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 143us/sample - loss: 0.0405\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 169us/sample - loss: 0.0342\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 167us/sample - loss: 0.0296\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 136us/sample - loss: 0.0259\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 151us/sample - loss: 0.0227\n",
      "The value of delta_label of current 3 th iteration is 0.1052292217422142 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 160us/sample - loss: 0.0829\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 139us/sample - loss: 0.0664\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 131us/sample - loss: 0.0544\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 180us/sample - loss: 0.0455\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 6s 180us/sample - loss: 0.0389\n",
      "The value of delta_label of current 4 th iteration is 0.07176478173963505 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 163us/sample - loss: 0.1694\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 154us/sample - loss: 0.1347\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 169us/sample - loss: 0.1127\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 159us/sample - loss: 0.0977\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 163us/sample - loss: 0.0867\n",
      "The value of delta_label of current 5 th iteration is 0.06299567992778386 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 169us/sample - loss: 0.2659\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 6s 192us/sample - loss: 0.2233\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 195us/sample - loss: 0.1948\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 180us/sample - loss: 0.1739\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 156us/sample - loss: 0.1578\n",
      "The value of delta_label of current 6 th iteration is 0.04829453865497453 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 172us/sample - loss: 0.3148\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.2731\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 159us/sample - loss: 0.2451\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 162us/sample - loss: 0.2242\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 174us/sample - loss: 0.2079\n",
      "The value of delta_label of current 7 th iteration is 0.02521116770907215 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 166us/sample - loss: 0.3230\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 154us/sample - loss: 0.2890\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 158us/sample - loss: 0.2661\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 151us/sample - loss: 0.2491\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 152us/sample - loss: 0.2353\n",
      "The value of delta_label of current 8 th iteration is 0.012154233025984913 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 166us/sample - loss: 0.3097\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 166us/sample - loss: 0.2860\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 183us/sample - loss: 0.2701\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 191us/sample - loss: 0.2578\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 174us/sample - loss: 0.2475\n",
      "The value of delta_label of current 9 th iteration is 0.006351150944612805 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 128us/sample - loss: 0.2913\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 152us/sample - loss: 0.2759\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 141us/sample - loss: 0.2652\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 136us/sample - loss: 0.2562\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 139us/sample - loss: 0.2483\n",
      "The value of delta_label of current 10 th iteration is 0.002966019730479077 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 167us/sample - loss: 0.2740\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 6s 182us/sample - loss: 0.2641\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 188us/sample - loss: 0.2569\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 192us/sample - loss: 0.2503\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 171us/sample - loss: 0.2442\n",
      "delta_label  0.0009671803468953511 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "The final prediction cluster is:\n",
      "0     1919\n",
      "1     2143\n",
      "2     2145\n",
      "3     3369\n",
      "4     2428\n",
      "5     2506\n",
      "6     2638\n",
      "7     1924\n",
      "8     3139\n",
      "9     3072\n",
      "10    1909\n",
      "11    2193\n",
      "12     816\n",
      "13     817\n",
      "dtype: int64\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 11358)]           0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 64)                726976    \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 14)                448       \n",
      "=================================================================\n",
      "Total params: 729,504\n",
      "Trainable params: 729,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.7)is: 338.77129101753235\n",
      "umap finished and added X_umap0.7  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.8\n",
      "The number of cpu in your computer is 32\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Checking whether /home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/Integrated/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.06341814994812012\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.24040879489328776 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 154us/sample - loss: 0.0185\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 130us/sample - loss: 0.0151\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.0133\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 149us/sample - loss: 0.0120\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 154us/sample - loss: 0.0110\n",
      "The value of delta_label of current 2 th iteration is 0.1385969437101038 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 160us/sample - loss: 0.0408\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 166us/sample - loss: 0.0347\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 164us/sample - loss: 0.0303\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 157us/sample - loss: 0.0266\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 150us/sample - loss: 0.0235\n",
      "The value of delta_label of current 3 th iteration is 0.0992004642465665 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 164us/sample - loss: 0.0817\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 163us/sample - loss: 0.0663\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 178us/sample - loss: 0.0550\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 165us/sample - loss: 0.0465\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 142us/sample - loss: 0.0402\n",
      "The value of delta_label of current 4 th iteration is 0.07618157199045715 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 6s 205us/sample - loss: 0.1644\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 7s 220us/sample - loss: 0.1323\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 175us/sample - loss: 0.1118\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 188us/sample - loss: 0.0975\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 159us/sample - loss: 0.0869\n",
      "The value of delta_label of current 5 th iteration is 0.06931459152750016 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 147us/sample - loss: 0.2620\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 147us/sample - loss: 0.2216\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 154us/sample - loss: 0.1941\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 129us/sample - loss: 0.1739\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 123us/sample - loss: 0.1581\n",
      "The value of delta_label of current 6 th iteration is 0.05132503707524663 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 137us/sample - loss: 0.3175\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 126us/sample - loss: 0.2776\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 137us/sample - loss: 0.2501\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 144us/sample - loss: 0.2294\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 145us/sample - loss: 0.2130\n",
      "The value of delta_label of current 7 th iteration is 0.031175446514926815 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 6s 186us/sample - loss: 0.3330\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 6s 208us/sample - loss: 0.2998\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 177us/sample - loss: 0.2769\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 141us/sample - loss: 0.2592\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 139us/sample - loss: 0.2450\n",
      "The value of delta_label of current 8 th iteration is 0.014701141272809337 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 4s 142us/sample - loss: 0.3265\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 133us/sample - loss: 0.3022\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 4s 131us/sample - loss: 0.2861\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 121us/sample - loss: 0.2729\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 4s 128us/sample - loss: 0.2619\n",
      "The value of delta_label of current 9 th iteration is 0.008640144432265136 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 163us/sample - loss: 0.3126\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 5s 167us/sample - loss: 0.2966\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 147us/sample - loss: 0.2858\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 4s 141us/sample - loss: 0.2751\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 145us/sample - loss: 0.2657\n",
      "The value of delta_label of current 10 th iteration is 0.004094396801856986 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 175us/sample - loss: 0.2971\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 6s 182us/sample - loss: 0.2860\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 192us/sample - loss: 0.2776\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 6s 184us/sample - loss: 0.2697\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 6s 198us/sample - loss: 0.2624\n",
      "The value of delta_label of current 11 th iteration is 0.002482429557031401 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 6s 196us/sample - loss: 0.2817\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 7s 213us/sample - loss: 0.2737\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 6s 179us/sample - loss: 0.2679\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 3s 102us/sample - loss: 0.2616\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 3s 97us/sample - loss: 0.2556\n",
      "The value of delta_label of current 12 th iteration is 0.0010316590366883744 >= tol 0.001\n",
      "Train on 31018 samples\n",
      "Epoch 1/5\n",
      "31018/31018 [==============================] - 5s 151us/sample - loss: 0.2670\n",
      "Epoch 2/5\n",
      "31018/31018 [==============================] - 4s 142us/sample - loss: 0.2611\n",
      "Epoch 3/5\n",
      "31018/31018 [==============================] - 5s 163us/sample - loss: 0.2563\n",
      "Epoch 4/5\n",
      "31018/31018 [==============================] - 5s 165us/sample - loss: 0.2516\n",
      "Epoch 5/5\n",
      "31018/31018 [==============================] - 5s 147us/sample - loss: 0.2471\n",
      "delta_label  0.000322393448965117 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "The final prediction cluster is:\n",
      "0     1852\n",
      "1     2221\n",
      "2     1433\n",
      "3     3355\n",
      "4     2114\n",
      "5     2362\n",
      "6     1818\n",
      "7     3359\n",
      "8     2183\n",
      "9     1841\n",
      "10    2876\n",
      "11    2453\n",
      "12     740\n",
      "13    1816\n",
      "14     595\n",
      "dtype: int64\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 11358)]           0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 64)                726976    \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 15)                480       \n",
      "=================================================================\n",
      "Total params: 729,536\n",
      "Trainable params: 729,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.8)is: 383.7075390815735\n",
      "umap finished and added X_umap0.8  into the umap coordinates (adata.obsm)\n",
      "\n",
      "The run time for all resolution is: 4896.351072311401\n",
      "After training, the information of adata is:\n",
      " AnnData object with n_obs × n_vars = 31018 × 11358\n",
      "    obs: 'CellFromTumor', 'PatientNumber', 'TumorType', 'n_counts', 'desc_0.4', 'desc_0.5', 'desc_0.6', 'desc_0.7', 'desc_0.8'\n",
      "    var: 'gene_id', 'mt', 'rb', 'gene_biotype', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'log1p_mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'log1p_total_counts-0', 'highly_variable-0', 'means-0', 'dispersions-0', 'dispersions_norm-0', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'log1p_mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'log1p_total_counts-1', 'highly_variable-1', 'means-1', 'dispersions-1', 'dispersions_norm-1', 'n_cells-2', 'n_cells_by_counts-2', 'mean_counts-2', 'log1p_mean_counts-2', 'pct_dropout_by_counts-2', 'total_counts-2', 'log1p_total_counts-2', 'highly_variable-2', 'means-2', 'dispersions-2', 'dispersions_norm-2', 'n_cells-3', 'n_cells_by_counts-3', 'mean_counts-3', 'log1p_mean_counts-3', 'pct_dropout_by_counts-3', 'total_counts-3', 'log1p_total_counts-3', 'highly_variable-3', 'means-3', 'dispersions-3', 'dispersions_norm-3'\n",
      "    uns: 'log1p', 'umap', 'prob_matrix0.4', 'prob_matrix0.5', 'prob_matrix0.6', 'prob_matrix0.7', 'prob_matrix0.8'\n",
      "    obsm: 'X_pca', 'X_umap', 'X_Embeded_z0.4', 'X_umap0.4', 'X_Embeded_z0.5', 'X_umap0.5', 'X_Embeded_z0.6', 'X_umap0.6', 'X_Embeded_z0.7', 'X_umap0.7', 'X_Embeded_z0.8', 'X_umap0.8'\n",
      "    obsp: 'distances', 'connectivities'\n"
     ]
    }
   ],
   "source": [
    "save_dir=\"/home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/Integrated\"\n",
    "adata2=desc.train(adata2,\n",
    "        dims=[adata.shape[1],64,32],\n",
    "        tol=0.001,\n",
    "        n_neighbors=10,\n",
    "        batch_size=256,\n",
    "        louvain_resolution=[0.4,0.5,0.6,0.7,0.8],# not necessarily a list, you can only set one value, like, louvain_resolution=1.0\n",
    "        save_dir=str(save_dir),\n",
    "        do_tsne=False,\n",
    "        learning_rate=200, # the parameter of tsne\n",
    "        use_GPU=False,\n",
    "        num_Cores=30, #for reproducible, only use 1 cpu\n",
    "        num_Cores_tsne=4,\n",
    "        save_encoder_weights=False,\n",
    "        save_encoder_step=3,# save_encoder_weights is False, this parameter is not used\n",
    "        use_ae_weights=False,\n",
    "        do_umap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2.write(\"/home/spuccio/isilon/spuccio/SP025_NaClTcell/Analysis/Integrated/Desc_T_cell.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 31018 × 11358\n",
       "    obs: 'CellFromTumor', 'PatientNumber', 'TumorType', 'n_counts', 'desc_0.4', 'desc_0.5', 'desc_0.6', 'desc_0.7', 'desc_0.8'\n",
       "    var: 'gene_id', 'mt', 'rb', 'gene_biotype', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'log1p_mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'log1p_total_counts-0', 'highly_variable-0', 'means-0', 'dispersions-0', 'dispersions_norm-0', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'log1p_mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'log1p_total_counts-1', 'highly_variable-1', 'means-1', 'dispersions-1', 'dispersions_norm-1', 'n_cells-2', 'n_cells_by_counts-2', 'mean_counts-2', 'log1p_mean_counts-2', 'pct_dropout_by_counts-2', 'total_counts-2', 'log1p_total_counts-2', 'highly_variable-2', 'means-2', 'dispersions-2', 'dispersions_norm-2', 'n_cells-3', 'n_cells_by_counts-3', 'mean_counts-3', 'log1p_mean_counts-3', 'pct_dropout_by_counts-3', 'total_counts-3', 'log1p_total_counts-3', 'highly_variable-3', 'means-3', 'dispersions-3', 'dispersions_norm-3'\n",
       "    uns: 'log1p', 'umap', 'prob_matrix0.4', 'prob_matrix0.5', 'prob_matrix0.6', 'prob_matrix0.7', 'prob_matrix0.8'\n",
       "    obsm: 'X_pca', 'X_umap', 'X_Embeded_z0.4', 'X_umap0.4', 'X_Embeded_z0.5', 'X_umap0.5', 'X_Embeded_z0.6', 'X_umap0.6', 'X_Embeded_z0.7', 'X_umap0.7', 'X_Embeded_z0.8', 'X_umap0.8'\n",
       "    obsp: 'distances', 'connectivities'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (desc)",
   "language": "python",
   "name": "desc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
